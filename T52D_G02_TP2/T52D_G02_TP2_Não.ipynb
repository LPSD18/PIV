{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By_UqSgduMNR"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://2223moodle.isel.pt/pluginfile.php/1/theme_adaptable/logo/1631635830/logo-isel_inv3.png\" width=\"250\">\n",
    "<h3>Licenciatura em Engenharia Informática e Multimédia</h3><br>\n",
    "<br>\n",
    "<h2>Processamento de Imagem e Visão (PIV)</h3>\n",
    "<h3>2º Trabalho Laboratorial – Estimação e classificação de movimento </h3>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "Trabalho Realizado por:<br>\n",
    "Gonçalo Silva <b>A48328</b><br>\n",
    "Diogo Lobo <b>A48168</b><br>\n",
    "Turma 52D<br><br>\n",
    "Docente: João Pedro Costa <br>\n",
    "<br>\n",
    "27 de Novembro 2024\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkIrTuiyM9xJ"
   },
   "source": [
    "***\n",
    "\n",
    "<br>\n",
    "<a id='section0'></a>\n",
    "<center><h2><b>Índice</b></2></center>\n",
    "\n",
    "- [Introdução](#section1)\n",
    "- [Desenvolvimento](#section2)\n",
    "  - [Deteção de Movimento](#section3)\n",
    "  - [Deteção de Contornos](#section4)\n",
    "  - [Deteção da Mão](#section5)\n",
    "  - [Implementação da Interação](#section6)\n",
    "- [Conclusão](#section7)\n",
    "- [Bibliografia](#section8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plceIUrDOOEs"
   },
   "source": [
    "***\n",
    "\n",
    "<a id='section1'></a>\n",
    "## <center><b>Introdução</b></center>\n",
    "<div style=\"text-align: justify\">\n",
    "<h3> Enquadramento</h3>\n",
    "\n",
    "No contexto da Unidade Curricular de Processamento de Imagem e Visão, foi proposto como segundo trabalho o desenvolvimento de um algoritmo de estimação e classificação de movimento para integração numa aplicação gráfica interativa;<br>\n",
    "\n",
    "<h3> Objetivo</h3>\n",
    "\n",
    "Pretende-se desenvolver um algoritmo que, ao utilizar a camara do computador, seja possivel mover um objeto com gestos da mão humana utilizando a interface Pygame.\n",
    "\n",
    "<h3> Métodos</h3>\n",
    "\n",
    "Para o desenvolvimento deste segundo trabalho é necessário utilizar python e várias bibliotecas como opencv, numpy, time e pygame. É tambem necessário uma câmara para que se possa realizar a interação entre o algoritmo e o ser humano.<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRnB4auduMNS",
    "outputId": "bc839ed1-4785-4c80-e02a-99c639748dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pygame\n",
    "from pygame.locals import QUIT\n",
    "from pygame import surfarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJso4Ez0aYgH"
   },
   "source": [
    "***\n",
    "<a id='section2'></a>\n",
    "# <center><b>Desenvolvimento</b></center>\n",
    "<div style=\"text-align: justify\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGMU4haHawHc"
   },
   "source": [
    "Valores utilizados para o funcionamento do trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPngwwwIuMNT"
   },
   "outputs": [],
   "source": [
    "#Inicialização dos tamanhos da janela e objetos\n",
    "window_width = 1280\n",
    "window_height = 700\n",
    "cube_size = 50\n",
    "cube_x = window_width // 4 - cube_size\n",
    "cube_y = window_height // 2 - cube_size\n",
    "cube_color = (0, 0, 255)\n",
    "previousContour = None\n",
    "radius = 20\n",
    "cyNew = None\n",
    "cxNew = None\n",
    "cxOld = None\n",
    "cyOld = None\n",
    "oldArea = None\n",
    "newArea = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fRZ5hy5b3NN"
   },
   "source": [
    "<a id='section3'></a>\n",
    "# <center><b>Deteção de Movimento</b></center>\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "O primeiro passo realizado no nosso trabalho foi a familiarização com o pygame, e deteção de movimento em geral. Assim, com os exercícios práticos realizados em aula fizemos um simples teste que permite detectar qualquer movimento e mostrar os resultados numa janela de pygame.\n",
    "\n",
    "Nesta porção de código utilizando a camara do computador é verificada a cada frame se houve uma mudança a comparar com a frame anterior e assinala com um quadrado vermelho, caso exista uma diferença, o local dessa diferença.\n",
    "\n",
    "Para que isto seja possivel é utilizado o threshold da frame para destacar áreas com mudanças significativas e analisando os componentes assinalados com a função *connectedComponentsWithStats*. Com o que se obtem desta função é possivel comparar as duas frames para alteração entre as frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "654si18Zr5J8"
   },
   "outputs": [],
   "source": [
    "#Start da camara\n",
    "camera = 0\n",
    "cam = cv2.VideoCapture(camera)\n",
    "\n",
    "running = True\n",
    "\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "window = pygame.display.set_mode((window_width, window_height))\n",
    "pygame.display.set_caption(\"Webcam in Pygame\")\n",
    "\n",
    "running = True\n",
    "fonte = pygame.font.SysFont(\"Arial\", 32)\n",
    "previousFrame = None\n",
    "thr = 10\n",
    "kernelSize = 9\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(kernelSize,kernelSize),(-1,-1))\n",
    "\n",
    "if cam.isOpened():\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        flag, frame = cam.read()\n",
    "        if flag:\n",
    "\n",
    "            frameE = cv2.medianBlur(frame,kernelSize)\n",
    "\n",
    "            if previousFrame is None:\n",
    "                previousFrame = frame\n",
    "\n",
    "            diff_image = cv2.absdiff(frame,previousFrame)\n",
    "            _ ,bw1 = cv2.threshold(diff_image,thr,255,cv2.THRESH_BINARY)\n",
    "            _, bw2 = cv2.threshold(np.uint8(bw1.sum(axis=2)),1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "            erode_image = cv2.erode(bw2,kernel)\n",
    "            dilate_image = cv2.dilate(erode_image,kernel,iterations=2)\n",
    "\n",
    "            (num_labels,label_image,stats,centroids) = cv2.connectedComponentsWithStats(dilate_image)\n",
    "\n",
    "            previousFrame = frame.copy()\n",
    "\n",
    "            motionFlag = False\n",
    "\n",
    "            for i in range(1,num_labels):\n",
    "                if(stats[i,4]>0.05*bw2.shape[0]*bw2.shape[1]):\n",
    "                    cv2.rectangle(frame,(stats[i,0],stats[i,1]),(stats[i,0]+stats[i,2],stats[i,1]+stats[i,3]),(0,0,255),thickness=2)\n",
    "                    motionFlag = True\n",
    "\n",
    "            if motionFlag:\n",
    "                texto_surface = fonte.render(\"Motion Detected\", True, (255, 0, 0))  # Texto em vermelho\n",
    "                window.blit(texto_surface, (10, 10))  # Posição do texto\n",
    "\n",
    "            ##### Vizualização da câmara no Pygame e sua localização ######\n",
    "\n",
    "            # Converte de BGR (OpenCV) para RGB (Pygame)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.rot90(frame)  # Pygame espera a imagem transposta\n",
    "            pygame_surface = pygame.surfarray.make_surface(frame)\n",
    "            window.blit(pygame_surface, (window_width // 2, window_height // 7))  # Centraliza no ecrã\n",
    "\n",
    "        pygame.display.update()  # Atualiza o ecrã\n",
    "\n",
    "    cam.release()\n",
    "    pygame.quit()\n",
    "\n",
    "else:\n",
    "    print(\"Error: Could not open Camera\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoH_caoyr7th"
   },
   "source": [
    "<a id='section4'></a>\n",
    "# <center><b>Deteção de Contornos</b></center>\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "Agora com uma ideia acerca de como detectar movimentos, inciamos o próximo passo, ***deteção da mão***. Para isto começamos por explorar o método GoodFeaturesToTrack.\n",
    "\n",
    "O método goodFeaturesToTrack() é utilizado para detetar pontos de interesse em imagens, como arestas e cantos, que são estáveis e fáceis de seguir em sequências de vídeo.\n",
    "\n",
    "No entanto não é suficiente para detetar a mão, assim, para garantir que a deteção se concentra exclusivamente na mão, realizamos uma segmentação baseada na cor da pele (opção b do H.3). Esse processo de segmentação permite ajudar na isolação da mão do restante da imagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvLv-DZzsEiD"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "# Iniciar a câmara e Pygame\n",
    "pygame.init()\n",
    "cap = cv2.VideoCapture(0)\n",
    "window = pygame.display.set_mode((window_width, window_height))\n",
    "pygame.display.set_caption(\"Hand Detection with GoodFeaturesToTrack1\")\n",
    "\n",
    "running = True\n",
    "\n",
    "while running:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Converte a imagem para escala de cinzento\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Segmentação baseada na cor da pele (opcional)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "    # Aplica a máscara e detecta as características\n",
    "    masked_gray = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "\n",
    "    # Detecta características usando goodFeaturesToTrack\n",
    "    corners = cv2.goodFeaturesToTrack(masked_gray, maxCorners=50, qualityLevel=0.01, minDistance=10)\n",
    "    if corners is not None:\n",
    "        for corner in corners:\n",
    "            x, y = corner.ravel()\n",
    "            cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)  # Desenha círculos nos pontos detectados\n",
    "\n",
    "    # Exibe a imagem com os pontos detectados no Pygame\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_rgb = np.rot90(frame_rgb)\n",
    "    pygame_surface = pygame.surfarray.make_surface(frame_rgb)\n",
    "    window.blit(pygame_surface, (0, 0))\n",
    "    pygame.display.update()\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "cap.release()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akxxrynRuMNT"
   },
   "source": [
    "<a id='section5'></a>\n",
    "# <center><b>Deteção da Mão</b></center>\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "Com os resultados obtidos anteriormente, observou-se que múltiplos contornos eram detetados na imagem, o que dificultava a precisão do algoritmo. Contudo, para alcançar o objetivo de detetar exclusivamente a mão, adotou-se a estratégia de considerar apenas o **maior contorno** detetado em cada frame.\n",
    "\n",
    "A suposição subjacente é que a mão será o maior objeto em movimento no campo de visão, devido ao seu destaque durante a interação com o sistema.\n",
    "Este procedimento aumenta a precisão do sistema ao eliminar detecções irrelevantes, como pequenos objetos ou ruídos que possam estar presentes no ambiente.\n",
    "\n",
    "Por se utilizar a cor para a segmentação é capaz de existir locais onde não funcione muito bem pelo fundo ter uma cor existente no intervalo ou ao utilizar uma luz amarela tambem piora os resultados obtidos no trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5mk_oU5uMNT"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "# Inicia a câmara e Pygame\n",
    "pygame.init()\n",
    "cap = cv2.VideoCapture(0)\n",
    "window = pygame.display.set_mode((window_width, window_height))\n",
    "pygame.display.set_caption(\"Hand Detection with GoodFeaturesToTrack\")\n",
    "fonte = pygame.font.SysFont(\"Arial\", 64)\n",
    "\n",
    "running = True\n",
    "\n",
    "while running:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Converte a imagem para o espaço HSV e escala de cinzento\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Segmentação baseada na cor da pele\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "\n",
    "    mask = cv2.erode(mask, np.ones((3, 3), np.uint8), iterations=2)\n",
    "    mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=2)\n",
    "\n",
    "    # Encontra contornos da máscara\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Inicializa flag para verificar se a mão foi detectada\n",
    "    hand_detected = False\n",
    "\n",
    "    if contours:\n",
    "        # Seleciona o maior contorno, assumindo que é a mão\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > 5000:  # Filtra áreas pequenas (ajustar conforme necessário)\n",
    "            hand_detected = True\n",
    "\n",
    "            # Desenha o contorno da mão\n",
    "            cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "            # Cria uma máscara apenas para a mão detetada\n",
    "            hand_mask = np.zeros_like(mask)\n",
    "            cv2.drawContours(hand_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "            # Aplica a máscara da mão à imagem em escala de cinzento\n",
    "            hand_region = cv2.bitwise_and(gray, gray, mask=hand_mask)\n",
    "\n",
    "            # Detecta características usando goodFeaturesToTrack apenas na região da mão\n",
    "            corners = cv2.goodFeaturesToTrack(hand_region, maxCorners=50, qualityLevel=0.01, minDistance=10)\n",
    "            if corners is not None:\n",
    "                for corner in corners:\n",
    "                    x, y = corner.ravel()\n",
    "                    cv2.circle(frame, (int(x), int(y)), 5, (0, 0, 255), -1)  # Desenha círculos nos pontos detectados\n",
    "\n",
    "    ##### Vizualização da câmara no Pygame e a sua localização #####\n",
    "\n",
    "    # Converte de BGR (OpenCV) para RGB (Pygame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = np.rot90(frame)  # Pygame espera a imagem transposta\n",
    "    pygame_surface = pygame.surfarray.make_surface(frame)\n",
    "    window.fill((0, 0, 0))  # Limpa a tela antes de atualizar o frame\n",
    "    window.blit(pygame_surface, (window_width // 2, window_height // 7))  # Centraliza na tela\n",
    "\n",
    "    # Mostra o texto apenas se a mão for detetada\n",
    "    if hand_detected:\n",
    "        texto_surface = fonte.render(\"Hand Detected\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 520, 10))  # Posição do texto\n",
    "\n",
    "    pygame.display.update()\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "cap.release()\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9oVb6nxuMNU"
   },
   "source": [
    "<a id='section6'></a>\n",
    "# <center><b>Implementação da Interação</b></center>\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "\n",
    "Nesta fase, implementamos a interação da interface gráfica com base nos movimentos detectados da mão. A detecção de movimentos é realizada comparando a posição atual da mão com sua posição anterior (baseada no centroide do maior contorno detectado) e a área do contorno para operações de zoom.\n",
    "\n",
    "Movimentos Implementados:\n",
    "\n",
    "- Up (Para Cima):\n",
    "O movimento \"Up\" é realizado quando a posição vertical do centroide atual da mão (cyNew) é menor do que a posição vertical anterior (cyOld), com uma margem de pelo menos 10 pixels. Isto, para garantir que pequenos ruídos na detecção não sejam interpretados como movimento.\n",
    "\n",
    "- Down (Para Baixo):\n",
    "O movimento \"Down\" é acionado quando cyNew é maior que cyOld em pelo menos 10 pixels.\n",
    "\n",
    "- Left (Esquerda):\n",
    "O movimento \"Left\" ocorre quando a posição horizontal do centroide (cxNew) é menor que cxOld, com uma diferença de 10 pixels\n",
    "\n",
    "- Right (Direita):\n",
    "O movimento \"Right\" é detectado quando cxNew é maior que cxOld em pelo menos 10 pixels.\n",
    "\n",
    "Zoom:\n",
    "\n",
    "- Zoom In:\n",
    "O \"Zoom In\" é ativado quando a área do maior contorno atual (newArea) aumenta em pelo menos 2000 pixels em relação à área anterior (oldArea). Esse aumento indica que a mão está se aproximando da câmera.\n",
    "\n",
    "- Zoom Out:\n",
    "O \"Zoom Out\" ocorre quando newArea diminui em pelo menos 2000 pixels, indicando que a mão está se afastando da câmera.\n",
    "\n",
    "\n",
    "Restrições de Movimento:\n",
    "\n",
    "- Para evitar que o objeto saia da área visível da interface, as funções canMove() verificam se o próximo movimento está dentro dos limites permitidos, através do raio do objeto e a posição atual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRGcfKPVuMNU"
   },
   "outputs": [],
   "source": [
    "def canMove(x,y,r,direction):\n",
    "    if(direction == 0):\n",
    "        return (y >= r)                 and ((y<= 250-r) or (x-r>=250) or (y>250+r))   and ((y<= 250-r) or (x+r<388) or (y>250+r))\n",
    "    if(direction == 1):\n",
    "        return (y <= window_height - r) and ((y<= 200-r) or (x-r>=250) or (y>200+r))   and ((y<= 200-r) or (x+r<388) or (y>200+r))\n",
    "    if(direction == 2):\n",
    "        return (x >= r)   and ((x - r >= 250) or not (200 - r <= y <= 250 + r))\n",
    "    if(direction == 3):\n",
    "        return (x <= window_width/2 - r) and ((x + r <= 388) or not (200 - r <= y <= 250 + r))\n",
    "\n",
    "def convImage(frame):\n",
    "    # Converte a imagem para o espaço HSV e escala de cinza\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Segmentação baseada na cor da pele\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "\n",
    "\n",
    "    mask = cv2.erode(mask, np.ones((3, 3), np.uint8), iterations=2)\n",
    "    mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=2)\n",
    "\n",
    "    # Encontra contornos da máscara\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return gray,mask,contours\n",
    "\n",
    "\n",
    "def moments(largest_contour):\n",
    "        Mnew = cv2.moments(largest_contour)\n",
    "        if Mnew['m00'] != 0:\n",
    "            cxNew = int(Mnew['m10'] / Mnew['m00'])\n",
    "            cyNew = int(Mnew['m01'] / Mnew['m00'])\n",
    "            newArea = cv2.contourArea(largest_contour)\n",
    "        else:\n",
    "            cxNew, cyNew, newArea = 0, 0, 0  # Fallback values\n",
    "\n",
    "        return cxNew,cyNew,newArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzYmj5-MuMNU"
   },
   "outputs": [],
   "source": [
    "# Inicia a câmara e Pygame\n",
    "pygame.init()\n",
    "cap = cv2.VideoCapture(0)\n",
    "window = pygame.display.set_mode((window_width, window_height))\n",
    "pygame.display.set_caption(\"Hand Detection with GoodFeaturesToTrack\")\n",
    "fonte = pygame.font.SysFont(\"Arial\", 64)\n",
    "fonte2 = pygame.font.SysFont(\"Arial\", 50)\n",
    "running = True\n",
    "player_pos = pygame.Vector2(window.get_width() // 4, window.get_height() // 2)\n",
    "dt = 0\n",
    "time.sleep(5)\n",
    "while running:\n",
    "    window.fill((0, 0, 0))\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray, mask, contours = convImage(frame)\n",
    "\n",
    "        # Inicializa flag para verificar se a mão foi detectada\n",
    "    hand_detected = False\n",
    "\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if cv2.contourArea(largest_contour) > 5000:\n",
    "            if previousContour is None:\n",
    "                previousContour = largest_contour.copy()\n",
    "            hand_detected = True\n",
    "\n",
    "            cxNew,cyNew,newArea = moments(largest_contour)\n",
    "\n",
    "            cxOld, cyOld, oldArea = moments(previousContour)\n",
    "\n",
    "            # Desenha o contorno da mão\n",
    "            cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "                # Cria uma máscara apenas para a mão detectada\n",
    "            hand_mask = np.zeros_like(mask)\n",
    "            cv2.drawContours(hand_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "                # Aplica a máscara da mão à imagem em escala de cinza\n",
    "            hand_region = cv2.bitwise_and(gray, gray, mask=hand_mask)\n",
    "\n",
    "                # Detecta características usando goodFeaturesToTrack apenas na região da mão\n",
    "            corners = cv2.goodFeaturesToTrack(hand_region, maxCorners=50, qualityLevel=0.01, minDistance=10)\n",
    "            if corners is not None:\n",
    "                for corner in corners:\n",
    "                    x, y = corner.ravel()\n",
    "                    cv2.circle(frame, (int(x), int(y)), 5, (0, 0, 255), -1)  # Desenha círculos nos pontos detectados\n",
    "\n",
    "        ##### Vizualização da câmara no Pygame e sua colocação #####\n",
    "\n",
    "        # Converte de BGR (OpenCV) para RGB (Pygame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = np.rot90(frame)  # Pygame espera a imagem transposta\n",
    "    pygame_surface = pygame.surfarray.make_surface(frame)\n",
    "    window.fill((0, 0, 0))  # Limpa a tela antes de atualizar o frame\n",
    "    window.blit(pygame_surface, (window_width // 2, window_height // 7))  # Centraliza na tela\n",
    "    pygame.draw.rect(window,(255,255,255),(0,200,250,50))\n",
    "    pygame.draw.rect(window,(255,255,255),(388,200,250,50))\n",
    "        # Mostra o texto apenas se a mão for detectada\n",
    "    if hand_detected:\n",
    "        texto_surface = fonte.render(\"Hand Detected\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 520, 10))  # Posição do texto\n",
    "    pygame.draw.circle(window, \"red\", player_pos, radius)\n",
    "    keys = pygame.key.get_pressed()\n",
    "    if keys[pygame.K_w] or (cyNew is not None and cyOld is not None and cyNew < cyOld + 5 and canMove(player_pos.x,player_pos.y, radius, 0)):\n",
    "        pygame.draw.rect(window, (0, 0, 0), (window_width - 250, window_height - 90, 200, 100))\n",
    "        player_pos.y -= 1000 * dt\n",
    "        texto_surface = fonte2.render(\"Up\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 250, window_height - 90))  # Posição do texto\n",
    "    if keys[pygame.K_s] or (cyNew is not None and cyOld is not None and cyNew + 5 > cyOld and canMove(player_pos.x,player_pos.y, radius, 1)):\n",
    "        pygame.draw.rect(window, (0, 0, 0), (window_width - 250, window_height - 90, 200, 100))\n",
    "        player_pos.y += 1000 * dt\n",
    "        texto_surface = fonte2.render(\"Down\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 250, window_height - 90))  # Posição do texto\n",
    "    if keys[pygame.K_a] or (cxNew is not None and cxOld is not None and cxNew + 5 > cxOld and canMove(player_pos.x,player_pos.y, radius, 2)):\n",
    "        pygame.draw.rect(window, (0, 0, 0), (window_width - 250, window_height - 90, 200, 100))\n",
    "        player_pos.x -= 1000 * dt\n",
    "        texto_surface = fonte2.render(\"Left\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 250, window_height - 90))  # Posição do texto\n",
    "    if keys[pygame.K_d] or (cxNew is not None and cxOld is not None and cxNew < cxOld + 5 and canMove(player_pos.x,player_pos.y, radius, 3)):\n",
    "        pygame.draw.rect(window, (0, 0, 0), (window_width - 250, window_height - 90, 200, 100))\n",
    "        player_pos.x += 1000 * dt\n",
    "        texto_surface = fonte2.render(\"Right\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 250, window_height - 90))  # Posição do texto\n",
    "    if keys[pygame.K_PLUS] or (newArea is not None and oldArea is not None and newArea + 750 > oldArea):\n",
    "        pygame.draw.rect(window, (0, 0, 0), (window_width - 250, window_height - 90, 200, 100))\n",
    "        if(radius<1000):\n",
    "            radius += 100 * dt\n",
    "        texto_surface = fonte2.render(\"Zoom In\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 250, window_height - 90))  # Posição do texto\n",
    "\n",
    "    if keys[pygame.K_MINUS] or (newArea is not None and oldArea is not None and newArea < oldArea + 750):\n",
    "        pygame.draw.rect(window, (0, 0, 0), (window_width - 250, window_height - 90, 200, 100))\n",
    "        if(radius>10):\n",
    "            radius -= 100 * dt\n",
    "        texto_surface = fonte2.render(\"Zoom Out\", True, (255, 0, 0))  # Texto em vermelho\n",
    "        window.blit(texto_surface, (window_width - 250, window_height - 90))  # Posição do texto\n",
    "\n",
    "\n",
    "    texto_surface = fonte.render(\"Movement:\", True, (255, 0, 0))  # Texto em vermelho\n",
    "    window.blit(texto_surface, (window_width - 600, window_height - 100))  # Posição do texto\n",
    "    previousContour = largest_contour.copy()\n",
    "\n",
    "\n",
    "    pygame.display.update()\n",
    "    dt = clock.tick(60) / 1000\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "cap.release()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_8muGgPtRgv"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySjtuFxRtSd7"
   },
   "source": [
    "<a id='section7'></a>\n",
    "# <center><b>Conclusão</b></center>\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "Em conclusão, este segundo trabalho prático permitiu-nos aplicar tanto os conceitos lecionados em aula como os exercicios práticos sobre estimação e classificação de movimento.\n",
    "\n",
    "Foi possivel utilizar o conhecimento do primeiro trabalho prático, mais precisamente sobre os contornos em 'imagens', neste caso as frames e aprofundar o conhecimento sobre o pygame que não foi muito utilizado neste curso.\n",
    "\n",
    "Existiram algumas dificuldades na realização do trabalho como no teste do algoritmo por funcionar melhor em certos locais comparando com outros o que dificultou ao testar o trabalho.\n",
    "\n",
    "Passadas estas dificuldades sentimos que realizámos um bom trabalho funcional onde é possivel movimentar uma bola utilizando a mão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63EjHjEM3_lF"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLP7TPCz4AtI"
   },
   "source": [
    "<a id='section8'></a>\n",
    "# <center><b>Bibliografia</b></center>\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "[Slides da unidade curricular disponibilizados pelos docentes;](https://2425moodle.isel.pt/course/view.php?id=8502)\\\n",
    "[Documentação OpenCV;](https://docs.opencv.org/4.x/index.html)\\\n",
    "[Documentação pygame;](https://www.pygame.org/docs/)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
